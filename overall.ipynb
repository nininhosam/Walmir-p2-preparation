{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf07a932",
   "metadata": {},
   "source": [
    "A seguir, vou te dar **um panorama claro, objetivo e (um pouco) detalhado**, suficiente para vocÃª se preparar para um exame tÃ©cnico sobre IA **voltado para RAG / NLP / vetores**.\n",
    "\n",
    "Vou explicar **cada etapa**, o **porquÃª**, **como funciona**, **o que Ã© esperado que vocÃª saiba**, e **ferramentas comuns (NLTK, ChromaDB, etc.)**.\n",
    "\n",
    "---\n",
    "\n",
    "# âœ… 1. Carregamento do Arquivo (PDF, CSV, JSON)\n",
    "\n",
    "Aqui vocÃª apenas **lÃª o arquivo** e extrai o texto / dados.\n",
    "\n",
    "* **PDF â†’** extraÃ§Ã£o de texto (pytesseract, pdfplumber, PyPDF2, pypdf)\n",
    "* **CSV â†’** pandas\n",
    "* **JSON â†’** leitura direta pelo Python (`json.load()`)\n",
    "\n",
    "O importante Ã©:\n",
    "**transformar tudo em texto cru** para o pipeline de processamento.\n",
    "\n",
    "---\n",
    "\n",
    "# âœ… 2. Processamento de Linguagem Natural (PLN)\n",
    "\n",
    "Objetivo: **limpar, normalizar e padronizar** o texto antes de criar embeddings.\n",
    "\n",
    "As etapas mais comuns:\n",
    "\n",
    "### 2.1 â€“ HomologaÃ§Ã£o (NormalizaÃ§Ã£o)\n",
    "\n",
    "Significa padronizar a forma como o texto estÃ¡ representado:\n",
    "\n",
    "* transformar tudo para **lowercase**\n",
    "* remover caracteres estranhos\n",
    "* normalizar acentos (opcional)\n",
    "* trocar â€œ\\n\\nâ€ por espaÃ§o simples\n",
    "* padronizar datas, nÃºmeros etc., se necessÃ¡rio\n",
    "\n",
    "### 2.2 â€“ Remover stop-words\n",
    "\n",
    "Stop-words = palavras que **nÃ£o carregam significado** relevante.\n",
    "\n",
    "Ex.: \"a\", \"o\", \"em\", \"de\", \"para\", â€œtheâ€, â€œatâ€, â€œonâ€, etc.\n",
    "\n",
    "Ferramentas comuns:\n",
    "\n",
    "* **NLTK** (`nltk.corpus.stopwords`)\n",
    "* **spaCy** (melhor)\n",
    "\n",
    "Obs.: *Para embeddings modernos, remover stopwords nem sempre Ã© necessÃ¡rio*, mas Ã© comum que o exame cobre esse conceito.\n",
    "\n",
    "### 2.3 â€“ TokenizaÃ§Ã£o\n",
    "\n",
    "Dividir o texto em:\n",
    "\n",
    "* palavras\n",
    "* frases\n",
    "* sentenÃ§as\n",
    "* tokens do modelo\n",
    "\n",
    "Ferramentas:\n",
    "\n",
    "* NLTK (`word_tokenize`)\n",
    "* spaCy\n",
    "\n",
    "### 2.4 â€“ LematizaÃ§Ã£o / StemizaÃ§Ã£o (opcional)\n",
    "\n",
    "Reduzir palavras Ã  sua forma base:\n",
    "\n",
    "* stemming: corta parte da palavra â†’ â€œplayingâ€ â†’ â€œplayâ€\n",
    "* lemmatization: forma correta â†’ â€œbetterâ€ â†’ â€œgoodâ€\n",
    "\n",
    "### 2.5 â€“ RemoÃ§Ã£o de ruÃ­do\n",
    "\n",
    "* remover HTML\n",
    "* remover sÃ­mbolos\n",
    "* remover espaÃ§os duplos\n",
    "* remover linhas vazias\n",
    "\n",
    "âœ“ No exame, basta mostrar que vocÃª entende **que o objetivo Ã© â€œlimpar e normalizar o textoâ€**.\n",
    "\n",
    "---\n",
    "\n",
    "# âœ… 3. Chunks (DivisÃ£o em pedaÃ§os)\n",
    "\n",
    "Depois que o texto estÃ¡ limpo, divide-se em **pedaÃ§os pequenos** para serem indexados individualmente.\n",
    "\n",
    "Por quÃª?\n",
    "\n",
    "* Embeddings tÃªm **limite de tokens**\n",
    "* Pesquisas ficam mais precisas quando os trechos sÃ£o menores\n",
    "* Ã‰ mais barato consultar / atualizar\n",
    "\n",
    "Formas comuns de chunking:\n",
    "\n",
    "* por nÃºmero de tokens (exemplo: 500â€“1000 tokens)\n",
    "* por nÃºmero de palavras (ex.: 300 palavras)\n",
    "* por sentenÃ§as\n",
    "* por parÃ¡grafos\n",
    "\n",
    "Ferramentas:\n",
    "\n",
    "* langchain â†’ `RecursiveCharacterTextSplitter`\n",
    "* manualmente no Python\n",
    "\n",
    "---\n",
    "\n",
    "# âœ… 4. Embeddings (o que sÃ£o)\n",
    "\n",
    "**Esta Ã© a parte mais importante.**\n",
    "\n",
    "Embeddings sÃ£o vetores numÃ©ricos (geralmente 384, 768, 1024 dimensÃµes) que representam o significado de um texto.\n",
    "\n",
    "Ou seja:\n",
    "**transformam palavras/sentenÃ§as/documentos em nÃºmeros que preservam semÃ¢ntica.**\n",
    "\n",
    "Ex.:\n",
    "\n",
    "```\n",
    "â€œgatoâ€ â†’ [0.12, 0.87, ... 0.03]\n",
    "â€œfelinoâ€ â†’ [0.11, 0.88, ... 0.02]  (muito parecido)\n",
    "â€œcarroâ€ â†’ [-0.33, 0.01, ... 0.77] (muito diferente)\n",
    "```\n",
    "\n",
    "Modelos comuns:\n",
    "\n",
    "* OpenAI `text-embedding-3-large`\n",
    "* SentenceTransformers (BERT, MiniLM)\n",
    "* Cohere\n",
    "* HuggingFace embeddings\n",
    "\n",
    "O que o exame espera:\n",
    "\n",
    "* Embeddings sÃ£o **representaÃ§Ãµes vetoriais** de texto\n",
    "* SÃ£o usados para **comparar semelhanÃ§a semÃ¢ntica**\n",
    "* Usam tÃ©cnicas como **cosine similarity**\n",
    "\n",
    "---\n",
    "\n",
    "# âœ… 5. Inserir no Banco de Dados Vetorial\n",
    "\n",
    "Banco vetorial = banco especializado em armazenar vetores.\n",
    "\n",
    "FunÃ§Ã£o:\n",
    "\n",
    "* guardar vetor + metadados (chunk original, id do documento, etc.)\n",
    "* permitir busca rÃ¡pida por similaridade\n",
    "\n",
    "Mais usados:\n",
    "\n",
    "* **ChromaDB** (muito simples)\n",
    "* Faiss (Facebook)\n",
    "* Pinecone\n",
    "* Milvus / Zilliz\n",
    "* Weaviate\n",
    "* Qdrant\n",
    "\n",
    "Com ChromaDB, por exemplo:\n",
    "\n",
    "```python\n",
    "client = chromadb.Client()\n",
    "\n",
    "collection = client.create_collection(\"meuarquivo\")\n",
    "\n",
    "collection.add(\n",
    "    embeddings=[vetor],\n",
    "    documents=[texto_do_chunk],\n",
    "    metadatas=[{\"origem\":\"pdf\"}],\n",
    "    ids=[\"chunk1\"]\n",
    ")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "# âœ… 6. Pesquisa / Busca semÃ¢ntica (Similarity Search)\n",
    "\n",
    "Funciona assim:\n",
    "\n",
    "1. VocÃª recebe uma *query* do usuÃ¡rio:\n",
    "   â€œQual Ã© o prazo de pagamento?â€\n",
    "2. Gera um embedding para a query\n",
    "3. Compara esse vetor com os vetores no banco\n",
    "4. Retorna os chunks mais parecidos (cosine similarity)\n",
    "5. (Opcional) Usa esses chunks para responder com RAG (LLM)\n",
    "\n",
    "Isso substitui **busca por palavra exata**, permitindo:\n",
    "\n",
    "* sinÃ´nimos\n",
    "* frases diferentes\n",
    "* aproximaÃ§Ã£o semÃ¢ntica\n",
    "\n",
    "---\n",
    "\n",
    "# âš¡ Resumo da Pipeline Completa\n",
    "\n",
    "```\n",
    "(1) Carregamento\n",
    "â†’ (2) NLP (clean, tokens, stopwords, normalizaÃ§Ã£o)\n",
    "â†’ (3) Chunks\n",
    "â†’ (4) Embeddings\n",
    "â†’ (5) InserÃ§Ã£o no banco vetorial\n",
    "â†’ (6) Similarity search (busca semÃ¢ntica)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "# ğŸ’¡ Extras Ãºteis que podem cair no exame\n",
    "\n",
    "A seguir algumas coisas â€œprovÃ¡veisâ€ que professores gostam de cobrar:\n",
    "\n",
    "## ğŸ”¹ Cosine similarity\n",
    "\n",
    "MÃ©trica usada para comparar embeddings.\n",
    "\n",
    "## ğŸ”¹ Por que chunk nÃ£o pode ser grande?\n",
    "\n",
    "* embeddings tÃªm limite de tokens\n",
    "* quanto maior o chunk, menos especÃ­fico\n",
    "\n",
    "## ğŸ”¹ Por que retirar stopwords?\n",
    "\n",
    "Simplifica o texto, remove ruÃ­do â†’ melhora embeddings antigos\n",
    "(Nos modernos, nÃ£o faz muita diferenÃ§a, mas ainda Ã© um conceito clÃ¡ssico de NLP).\n",
    "\n",
    "## ğŸ”¹ Qual a diferenÃ§a entre vetor e embedding?\n",
    "\n",
    "Todos embeddings sÃ£o vetores, mas vetores podem ser qualquer coisa.\n",
    "Embedding Ã© **vetor semÃ¢ntico gerado por modelo ML**.\n",
    "\n",
    "## ğŸ”¹ Embedding de palavras vs sentenÃ§as vs documentos\n",
    "\n",
    "* word embeddings (Word2Vec)\n",
    "* sentence embeddings (Sentence-BERT)\n",
    "* text embeddings (OpenAI embedding models)\n",
    "\n",
    "---\n",
    "\n",
    "# âš™ Ferramentas citadas no exame com frequÃªncia\n",
    "\n",
    "* **NLTK** â†’ stopwords, tokenizaÃ§Ã£o\n",
    "* **spaCy** â†’ melhor NLP industrial\n",
    "* **ChromaDB** â†’ banco vetorial\n",
    "* **SentenceTransformers** â†’ gerar embeddings locais\n",
    "* **LangChain** â†’ pipeline completa\n",
    "\n",
    "---\n",
    "\n",
    "Se quiser, posso te preparar:\n",
    "\n",
    "* ğŸ”¸ um **resumo para prova**\n",
    "* ğŸ”¸ um **mapa mental**\n",
    "* ğŸ”¸ perguntas e respostas provÃ¡veis\n",
    "* ğŸ”¸ exercÃ­cios prÃ¡ticos\n",
    "* ğŸ”¸ um passo a passo com **cÃ³digo explicado**\n",
    "\n",
    "Como prefere?\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
